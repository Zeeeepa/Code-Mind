"""API routes for Code-Mind."""
import uuid
from typing import Dict, List, Optional, Any
from fastapi import FastAPI, HTTPException, Body
from pydantic import BaseModel, Field

from code_mind.utils.logger import get_logger

logger = get_logger(__name__)

app = FastAPI(title="Code-Mind API", description="API for Code-Mind")

# In-memory storage for demo purposes
# In a real application, this would be a database
projects_db = {}
analysis_results_db = {}
reflection_results_db = {}

# Models
class ProjectBase(BaseModel):
    """Base model for project data."""
    name: str
    description: str = ""

class RequirementBase(BaseModel):
    """Base model for requirement data."""
    title: str
    description: str = ""
    priority: str = "Medium"

class Project(ProjectBase):
    """Project model with ID and requirements."""
    id: str
    requirements: List[Dict[str, Any]] = []

class AnalysisRequest(BaseModel):
    """Request model for code analysis."""
    repo_url: str
    analysis_type: str = "Comprehensive"

class ReflectionRequest(BaseModel):
    """Request model for project reflection."""
    reflection_type: str
    custom_prompt: Optional[str] = None

# Routes
@app.get("/")
async def root():
    """Root endpoint.

    Returns:
        A welcome message.
    """
    return {"message": "Welcome to Code-Mind API"}

@app.get("/health")
async def health():
    """Health check endpoint.

    Returns:
        The health status of the API.
    """
    return {"status": "healthy"}

@app.post("/projects", response_model=Project)
async def create_project(project: ProjectBase):
    """Create a new project.
    
    Args:
        project: Project data
        
    Returns:
        The created project
    """
    project_id = str(uuid.uuid4())
    project_data = {
        "id": project_id,
        "name": project.name,
        "description": project.description,
        "requirements": []
    }
    projects_db[project_id] = project_data
    logger.info(f"Created project: {project.name} (ID: {project_id})")
    return project_data

@app.get("/projects", response_model=List[Project])
async def list_projects():
    """List all projects.
    
    Returns:
        List of all projects
    """
    return list(projects_db.values())

@app.get("/projects/{project_id}", response_model=Project)
async def get_project(project_id: str):
    """Get a project by ID.
    
    Args:
        project_id: Project ID
        
    Returns:
        The project data
    """
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")
    return projects_db[project_id]

@app.post("/projects/{project_id}/requirements", response_model=Project)
async def add_requirement(project_id: str, requirement: RequirementBase):
    """Add a requirement to a project.
    
    Args:
        project_id: Project ID
        requirement: Requirement data
        
    Returns:
        The updated project
    """
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")
    
    req_id = str(uuid.uuid4())
    req_data = {
        "id": req_id,
        "title": requirement.title,
        "description": requirement.description,
        "priority": requirement.priority
    }
    
    projects_db[project_id]["requirements"].append(req_data)
    logger.info(f"Added requirement to project {project_id}: {requirement.title}")
    return projects_db[project_id]

@app.post("/projects/{project_id}/analyze")
async def analyze_project(project_id: str, analysis: AnalysisRequest):
    """Analyze a project's code.
    
    Args:
        project_id: Project ID
        analysis: Analysis request data
        
    Returns:
        Analysis results
    """
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # In a real application, this would call an LLM or code analysis service
    # For demo purposes, we'll return mock data
    analysis_id = str(uuid.uuid4())
    
    # Mock analysis results
    results = {
        "id": analysis_id,
        "project_id": project_id,
        "repo_url": analysis.repo_url,
        "analysis_type": analysis.analysis_type,
        "summary": "This is a mock analysis of the codebase. In a real application, this would be generated by an LLM or code analysis service.",
        "metrics": {
            "code_quality": 85,
            "maintainability": 78,
            "security": 92,
            "test_coverage": 65
        },
        "findings": {
            "code_quality": [
                {
                    "title": "Complex function in auth module",
                    "description": "The authenticate function has a cyclomatic complexity of 15, which is above the recommended threshold of 10.",
                    "location": {
                        "file": "auth.py",
                        "line": 42
                    }
                },
                {
                    "title": "Long method in data processing",
                    "description": "The process_data method is 150 lines long, consider breaking it down into smaller functions.",
                    "location": {
                        "file": "data_processor.py",
                        "line": 78
                    }
                }
            ],
            "security": [
                {
                    "title": "Potential SQL injection",
                    "description": "User input is directly concatenated into SQL query without proper parameterization.",
                    "location": {
                        "file": "database.py",
                        "line": 127
                    }
                }
            ]
        }
    }
    
    analysis_results_db[analysis_id] = results
    logger.info(f"Analyzed project {project_id} with repo {analysis.repo_url}")
    return results

@app.post("/projects/{project_id}/reflect")
async def reflect_on_project(project_id: str, reflection: ReflectionRequest):
    """Generate a reflection on a project.
    
    Args:
        project_id: Project ID
        reflection: Reflection request data
        
    Returns:
        Reflection results
    """
    if project_id not in projects_db:
        raise HTTPException(status_code=404, detail="Project not found")
    
    # In a real application, this would call an LLM
    # For demo purposes, we'll return mock data
    reflection_id = str(uuid.uuid4())
    
    # Get project data for context
    project = projects_db[project_id]
    
    # Mock reflection based on type
    reflection_text = ""
    recommendations = []
    
    if reflection.reflection_type == "Requirements Analysis":
        reflection_text = f"# Requirements Analysis for {project['name']}\n\nBased on the current requirements, this project appears to be focused on [specific domain]. The requirements are generally well-defined, but there are some areas that could benefit from further clarification.\n\nThe high-priority requirements are appropriately focused on core functionality, while the lower-priority items address secondary features that can be implemented later."
        recommendations = [
            {
                "title": "Add Acceptance Criteria",
                "description": "Each requirement would benefit from explicit acceptance criteria to clarify when the requirement is considered 'done'.",
                "action_items": [
                    "Review each requirement and add 2-3 acceptance criteria",
                    "Ensure criteria are measurable and testable"
                ]
            },
            {
                "title": "Prioritize Technical Requirements",
                "description": "Consider adding non-functional requirements related to performance, security, and scalability.",
                "action_items": [
                    "Add performance benchmarks",
                    "Define security requirements",
                    "Specify supported platforms and browsers"
                ]
            }
        ]
    elif reflection.reflection_type == "Implementation Strategy":
        reflection_text = f"# Implementation Strategy for {project['name']}\n\nFor a project of this nature, an iterative development approach would be most suitable. I recommend starting with a minimal viable product (MVP) that addresses the core requirements, then expanding functionality in subsequent iterations.\n\nThe project can be broken down into several key components that can be developed in parallel by different team members."
        recommendations = [
            {
                "title": "Adopt Agile Methodology",
                "description": "Given the project scope and requirements, a Scrum or Kanban approach would provide the necessary flexibility.",
                "action_items": [
                    "Set up 2-week sprint cycles",
                    "Establish daily standups",
                    "Create a project backlog in a tracking system"
                ]
            },
            {
                "title": "Technical Architecture",
                "description": "Consider a microservices architecture to allow for independent scaling of different components.",
                "action_items": [
                    "Create architecture diagram",
                    "Define service boundaries",
                    "Establish API contracts between services"
                ]
            }
        ]
    elif reflection.reflection_type == "Technology Stack":
        reflection_text = f"# Technology Stack Recommendations for {project['name']}\n\nBased on the project requirements, I recommend the following technology stack:\n\n- **Frontend**: React with TypeScript for type safety and better developer experience\n- **Backend**: FastAPI (Python) for rapid API development with automatic documentation\n- **Database**: PostgreSQL for relational data, with Redis for caching\n- **Infrastructure**: Docker containers orchestrated with Kubernetes for scalability\n- **CI/CD**: GitHub Actions for continuous integration and deployment"
        recommendations = [
            {
                "title": "Frontend Framework Selection",
                "description": "React is recommended for its robust ecosystem and component-based architecture, but Vue.js could be an alternative if the team has more experience with it.",
                "action_items": [
                    "Assess team's experience with React vs Vue",
                    "Consider using Next.js for server-side rendering",
                    "Set up a component library like Material-UI or Tailwind"
                ]
            },
            {
                "title": "API Design",
                "description": "A RESTful API design with OpenAPI documentation would provide a clear interface for frontend integration.",
                "action_items": [
                    "Define API endpoints based on requirements",
                    "Implement versioning strategy",
                    "Set up automatic documentation with Swagger/OpenAPI"
                ]
            }
        ]
    else:  # Custom or fallback
        prompt = reflection.custom_prompt or f"Reflection on {project['name']}"
        reflection_text = f"# Custom Reflection: {prompt}\n\nThis is a custom reflection on the project. In a real application, this would be generated by an LLM based on the specific prompt and project context."
        recommendations = [
            {
                "title": "General Recommendation",
                "description": "This is a placeholder recommendation. In a real application, this would be generated by an LLM based on the specific prompt.",
                "action_items": [
                    "Custom action item 1",
                    "Custom action item 2"
                ]
            }
        ]
    
    results = {
        "id": reflection_id,
        "project_id": project_id,
        "reflection_type": reflection.reflection_type,
        "reflection": reflection_text,
        "recommendations": recommendations
    }
    
    reflection_results_db[reflection_id] = results
    logger.info(f"Generated {reflection.reflection_type} reflection for project {project_id}")
    return results
